{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=5, linewidth=150)\n",
    "import spax\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle Component Analysis (PCA)\n",
    "Let X be $n \\times m$ matrix, where $n$ represents dimensionality of the data and $m$ number of samples.\n",
    "To prepare data for the PCA, it should be centered `X -= X.mean(axis = 1)`, and possibly whitened `X /= X.std(axis = 1)`. Whitening is done to scale dimensions to unit variance. This is specifically useful if data dimensions are in different units or represent different observables. PCA then consists of finding a rotation matrix which makes covariance of the data diagonal. Specifically, PCA of order $N$ does this rotation for $N$ largest eigenvalues of the covariance matrix.\n",
    "\n",
    "## Singular Value Decomposition (SVD)\n",
    "Every non-quadratic matrix can be decomposed as $$X = U \\, S \\, V^T \\, ,$$ where $U$ is $n \\times m$ matrix with orthonormal columns ($U^T \\, U = I$), $V$ is $m \\times m$ orthonormal matrix ($V^T \\, V = I$) and $S$ a diagonal $m\\times m$ matrix of singular values. From such decomposition one can write\n",
    "\\begin{align}\n",
    "X \\, X^T &= U \\, S^2 \\, U^T  \\, , \\\\\n",
    "X^T X &= V \\, S^2 \\, V^T \\, .\n",
    "\\end{align}\n",
    "Both $X \\, X^T$ and $X^T X$ have the same eigenvalues, with larger of the two having the rest equal to $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case #1: $n < m$\n",
    "Covariance of the data can be written as $$ C = \\frac{1}{m-1} X \\, X^T = U \\, \\frac{S^2}{m-1} \\, U^T \\, .$$ Therefore, by solving an eigenvalue problem for $C$, we can find $U$. By picking $N$ eigenvectors in the directions of the largest eigenvalues, we construct $\\widetilde{U}$ used for PCA.\n",
    "\n",
    "For some matrix $X_0$ of size $n \\times m_0$, PCA is simply $$ Y_0 = \\widetilde{U}^T X_0$$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION: 0:00:03.665672\n",
      "[15.86349 15.01729 14.025   12.97456 11.96139]\n",
      "[15.88904 15.04109 14.00261 12.92626 12.06539]\n",
      "[15.86442 15.01822 14.02536 12.97476 11.96212]\n",
      "[[ 0.  -0.  -0.  -0.   0.  -0.   0.  -0.   0.  -0.   0.   0.   0.   0.  -0.1  1. ]\n",
      " [-0.  -0.  -0.   0.  -0.  -0.   0.  -0.   0.   0.  -0.  -0.  -0.  -0.1  1.   0.1]\n",
      " [-0.  -0.  -0.  -0.  -0.   0.  -0.  -0.   0.  -0.  -0.   0.  -0.1  1.   0.1 -0. ]\n",
      " [ 0.  -0.  -0.  -0.   0.  -0.   0.   0.   0.   0.  -0.  -0.   1.   0.1  0.  -0. ]\n",
      " [ 0.   0.   0.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.   1.   0.  -0.   0.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "N_dim, N_samples = (16, 10**5)\n",
    "pca = spax.PCA_m(5, devices = jax.devices(\"gpu\"))\n",
    "data = np.random.normal(0, 1, size = (N_dim, N_samples)) * np.sqrt(np.arange(1, N_dim + 1))[:, np.newaxis]\n",
    "tic = datetime.now()\n",
    "pca.fit(data, batch_size = N_dim // 2, centering_data = \"GPU\") # N_dim % (N_devices * batch_size) == 0\n",
    "print(\"DURATION:\", datetime.now() - tic)\n",
    "sampled_data = pca.sample(N_samples, batch_size = N_dim // 2)\n",
    "print(np.std(pca.transform(data, batch_size = N_dim // 2), axis = 1)**2) # should be [16, 15, 14, 13, 12]\n",
    "print(np.std(pca.transform(sampled_data, batch_size = N_dim // 2), axis = 1)**2) #should be the same\n",
    "print(pca.λ ** 2) # should be the same\n",
    "print(np.round(pca.U.T, 1)) # should be a +-unit matrix on last 5 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION: 0:00:00.258082\n",
      "[15.86399 15.01809 14.02532 12.97499 11.96181]\n",
      "[15.88819 15.03968 14.00197 12.92547 12.06467]\n",
      "[15.86415 15.01824 14.02546 12.97512 11.96193]\n",
      "[[-0.  -0.   0.   0.  -0.   0.   0.   0.  -0.   0.  -0.  -0.  -0.  -0.   0.1 -1. ]\n",
      " [-0.   0.  -0.   0.  -0.   0.  -0.  -0.  -0.  -0.   0.   0.   0.   0.1 -1.  -0.1]\n",
      " [-0.  -0.   0.  -0.  -0.   0.  -0.  -0.   0.  -0.  -0.   0.  -0.1  1.   0.1 -0. ]\n",
      " [-0.  -0.   0.  -0.  -0.   0.   0.  -0.  -0.  -0.   0.   0.  -1.  -0.1 -0.   0. ]\n",
      " [ 0.  -0.  -0.   0.  -0.  -0.   0.  -0.  -0.  -0.   0.   1.   0.  -0.   0.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "#testing the result with scikit-learn\n",
    "pca_sk = PCA(n_components = 5)\n",
    "tic = datetime.now()\n",
    "pca_sk.fit(data.T)\n",
    "print(\"DURATION:\", datetime.now() - tic)\n",
    "print(np.std(pca_sk.transform(data.T), axis = 0)**2)\n",
    "print(np.std(pca_sk.transform(sampled_data.T), axis = 0)**2)\n",
    "print(pca_sk.singular_values_**2 / (N_samples - 1))\n",
    "print(np.round(pca_sk.components_, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case #2 $n \\ge m$\n",
    "In this case, it is better to write: $$D = \\frac{1}{n} X^T \\, X = V \\, \\frac{S^2}{n} \\, V^T \\, .$$\n",
    "Solving eigenvector problem for $D$ gives us $V$ and $S$. Then, rotation matrix can be computed as $$ U = X \\, V \\, S^{-1} \\, .$$ The rest is the same as in previous case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION: 0:00:01.705780\n",
      "[3.20480e+08 3.18571e+08 3.17954e+08 3.16769e+08 3.16200e+08]\n",
      "[3.41459e+08 3.37940e+08 3.43414e+08 3.37691e+08 3.44295e+08]\n",
      "[3.41847e+08 3.39811e+08 3.39152e+08 3.37887e+08 3.37281e+08]\n",
      "[[ 6.33442e-06  8.16398e-06 -3.66614e-06 ...  3.28223e-03 -8.05994e-03  2.22728e-03]\n",
      " [ 4.32146e-06  2.09783e-05 -5.39127e-06 ...  4.88083e-03 -3.92408e-03  1.12816e-03]\n",
      " [-4.10747e-05  4.59198e-06  3.08347e-05 ...  4.53058e-03 -6.94469e-03 -3.38505e-03]\n",
      " [ 4.58250e-07  1.24855e-05  1.09394e-05 ...  5.18696e-03  9.30697e-04 -6.11469e-04]\n",
      " [-1.19243e-06 -2.17123e-05 -4.26089e-05 ... -3.43697e-03  1.93229e-03 -2.56672e-03]]\n"
     ]
    }
   ],
   "source": [
    "N_dim, N_samples = (10**5, 16)\n",
    "pca = spax.PCA_m(5, devices = jax.devices(\"gpu\"))\n",
    "data = np.random.normal(0, 1, size = (N_dim, N_samples)) * np.sqrt(np.arange(1, N_dim + 1))[:, np.newaxis]\n",
    "tic = datetime.now()\n",
    "pca.fit(data, batch_size = N_dim // 2, centering_data = \"GPU\") # N_dim % (N_devices * batch_size) == 0\n",
    "print(\"DURATION:\", datetime.now() - tic)\n",
    "sampled_data = pca.sample(10**4, batch_size = N_dim // 2)\n",
    "print(np.std(pca.transform(data, batch_size = N_dim // 2), axis = 1)**2)\n",
    "print(np.std(pca.transform(sampled_data, batch_size = N_dim // 2), axis = 1)**2)\n",
    "print(pca.λ ** 2)\n",
    "print(pca.U.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION: 0:00:00.166816\n",
      "[3.20481e+08 3.18571e+08 3.17954e+08 3.16769e+08 3.16200e+08]\n",
      "[3.41459e+08 3.37940e+08 3.43414e+08 3.37690e+08 3.44296e+08]\n",
      "[3.41846e+08 3.39809e+08 3.39151e+08 3.37887e+08 3.37281e+08]\n",
      "[[ 6.33356e-06  8.16345e-06 -3.66521e-06 ...  3.28216e-03 -8.06003e-03  2.22716e-03]\n",
      " [-4.31963e-06 -2.09781e-05  5.39206e-06 ... -4.88114e-03  3.92440e-03 -1.12789e-03]\n",
      " [ 4.10754e-05 -4.59016e-06 -3.08327e-05 ... -4.53029e-03  6.94427e-03  3.38534e-03]\n",
      " [ 4.60913e-07  1.24849e-05  1.09398e-05 ...  5.18659e-03  9.31135e-04 -6.11179e-04]\n",
      " [ 1.18826e-06  2.17128e-05  4.26083e-05 ...  3.43740e-03 -1.93294e-03  2.56633e-03]]\n"
     ]
    }
   ],
   "source": [
    "pca_sk = PCA(n_components = 5)\n",
    "tic = datetime.now()\n",
    "pca_sk.fit(data.T)\n",
    "print(\"DURATION:\", datetime.now() - tic)\n",
    "print(np.std(pca_sk.transform(data.T), axis = 0)**2)\n",
    "print(np.std(pca_sk.transform(sampled_data.T), axis = 0)**2)\n",
    "print(pca_sk.singular_values_**2 / (N_samples - 1))\n",
    "print(pca_sk.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test save + load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-71815.555   29139.97     3841.4258 -87116.92    23392.324 ]\n",
      "[-71815.555   29139.967    3841.4229 -87116.92    23392.318 ]\n",
      "[-71812.21997 -29130.60387  -3838.60998 -87106.1801  -23407.71851]\n"
     ]
    }
   ],
   "source": [
    "pca.save(\"test.hdf5\")\n",
    "pca_new = spax.PCA_m(5, devices = jax.devices(\"gpu\"))\n",
    "pca_new.load(\"test.hdf5\")\n",
    "\n",
    "x0 = np.arange(100000)[:, np.newaxis]\n",
    "print(pca.transform(x0, batch_size = N_dim // 2).flatten())\n",
    "print(pca_new.transform(x0, batch_size = N_dim // 2).flatten())\n",
    "print(pca_sk.transform(x0.T).flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}