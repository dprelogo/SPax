{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=5, linewidth=150)\n",
    "import spax\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle Component Analysis (PCA)\n",
    "Let X be $n \\times m$ matrix, where $n$ represents dimensionality of the data and $m$ number of samples.\n",
    "To prepare data for the PCA, it should be centered `X -= X.mean(axis = 1)`, and possibly whitened `X /= X.std(axis = 1)`. Whitening is done to scale dimensions to unit variance. This is specifically useful if data dimensions are in different units or represent different observables. PCA then consists of finding a rotation matrix which makes covariance of the data diagonal. Specifically, PCA of order $N$ does this rotation for $N$ largest eigenvalues of the covariance matrix.\n",
    "\n",
    "## Singular Value Decomposition (SVD)\n",
    "Every non-quadratic matrix can be decomposed as $$X = U \\, S \\, V^T \\, ,$$ where $U$ is $n \\times m$ matrix with orthonormal columns ($U^T \\, U = I$), $V$ is $m \\times m$ orthonormal matrix ($V^T \\, V = I$) and $S$ a diagonal $m\\times m$ matrix of singular values. From such decomposition one can write\n",
    "\\begin{align}\n",
    "X \\, X^T &= U \\, S^2 \\, U^T  \\, , \\\\\n",
    "X^T X &= V \\, S^2 \\, V^T \\, .\n",
    "\\end{align}\n",
    "Both $X \\, X^T$ and $X^T X$ have the same eigenvalues, with larger of the two having the rest equal to $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case #1: $n \\le m$\n",
    "Covariance of the data can be written as $$ C = \\frac{1}{m-1} X \\, X^T = U \\, \\frac{S^2}{m-1} \\, U^T \\, .$$ Therefore, by solving an eigenvalue problem for $C$, we can find $U$. By picking $N$ eigenvectors in the directions of the largest eigenvalues, we construct $\\widetilde{U}$ used for PCA.\n",
    "\n",
    "For some matrix $X_0$ of size $n \\times m_0$, PCA is simply $$ Y_0 = \\widetilde{U}^T X_0$$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION: 0:00:03.745769\n",
      "[16.00737 15.09035 13.97557 12.95597 11.96924]\n",
      "[15.9131  15.14852 13.93848 12.92286 11.9518 ]\n",
      "[16.00817 15.0917  13.97685 12.95663 11.97026]\n",
      "[[-0.   0.  -0.   0.   0.  -0.  -0.   0.   0.  -0.  -0.   0.  -0.  -0.   0.   1. ]\n",
      " [ 0.   0.  -0.  -0.   0.   0.  -0.   0.  -0.   0.  -0.   0.   0.  -0.   1.  -0. ]\n",
      " [-0.   0.  -0.   0.   0.  -0.   0.  -0.  -0.  -0.   0.   0.  -0.   1.   0.   0. ]\n",
      " [-0.   0.  -0.   0.  -0.  -0.   0.   0.   0.   0.  -0.  -0.1  1.   0.  -0.   0. ]\n",
      " [-0.  -0.   0.  -0.  -0.   0.   0.   0.  -0.   0.   0.   1.   0.1 -0.  -0.  -0. ]]\n"
     ]
    }
   ],
   "source": [
    "N_dim, N_samples = (16, 10**5)\n",
    "pca = spax.PCA_m(5, devices = jax.devices(\"gpu\"))\n",
    "data = np.random.normal(0, 1, size = (N_dim, N_samples)) * np.sqrt(np.arange(1, N_dim + 1))[:, np.newaxis]\n",
    "tic = datetime.now()\n",
    "pca.fit(data, batch_size = N_dim // 2, centering_data = \"GPU\") # N_dim % (N_devices * batch_size) == 0\n",
    "print(\"DURATION:\", datetime.now() - tic)\n",
    "sampled_data = pca.sample(N_samples, batch_size = N_dim // 2)\n",
    "print(np.std(pca.transform(data, batch_size = N_dim // 2), axis = 1)**2) # should be [8, 7, 6, 5, 4]\n",
    "print(np.std(pca.transform(sampled_data, batch_size = N_dim // 2), axis = 1)**2) #should be the same\n",
    "print(pca.λ ** 2) # should be the same\n",
    "print(np.round(pca.U.T, 1)) # should be a +-unit matrix on last 5 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION: 0:00:00.250611\n",
      "[16.00795 15.09157 13.97652 12.95648 11.97058]\n",
      "[15.91202 15.1465  13.93696 12.9219  11.94907]\n",
      "[16.00811 15.09173 13.97666 12.95661 11.9707 ]\n",
      "[[ 0.   0.  -0.   0.   0.  -0.   0.   0.   0.  -0.  -0.   0.  -0.  -0.   0.   1. ]\n",
      " [-0.  -0.   0.   0.   0.   0.  -0.  -0.  -0.   0.  -0.   0.   0.  -0.   1.  -0. ]\n",
      " [-0.  -0.  -0.   0.  -0.  -0.   0.  -0.  -0.  -0.   0.   0.  -0.   1.   0.   0. ]\n",
      " [ 0.  -0.  -0.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.   0.1 -1.  -0.   0.  -0. ]\n",
      " [-0.  -0.  -0.   0.  -0.  -0.   0.  -0.   0.  -0.  -0.  -1.  -0.1  0.   0.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "#testing the result with scikit-learn\n",
    "pca_sk = PCA(n_components = 5)\n",
    "tic = datetime.now()\n",
    "pca_sk.fit(data.T)\n",
    "print(\"DURATION:\", datetime.now() - tic)\n",
    "print(np.std(pca_sk.transform(data.T), axis = 0)**2)\n",
    "print(np.std(pca_sk.transform(sampled_data.T), axis = 0)**2)\n",
    "print(pca_sk.singular_values_**2 / (N_samples - 1))\n",
    "print(np.round(pca_sk.components_, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case #2 $n \\ge m$\n",
    "In this case, it is better to write: $$D = \\frac{1}{n} X^T \\, X = V \\, \\frac{S^2}{n} \\, V^T \\, .$$\n",
    "Solving eigenvector problem for $D$ gives us $V$ and $S$. Then, rotation matrix can be computed as $$ U = X \\, V \\, S^{-1} \\, .$$ The rest is the same as in previous case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION: 0:00:01.656207\n",
      "[3.19257e+08 3.18094e+08 3.17750e+08 3.16736e+08 3.15445e+08]\n",
      "[3.37049e+08 3.40064e+08 3.36459e+08 3.38866e+08 3.35253e+08]\n",
      "[3.40541e+08 3.39301e+08 3.38934e+08 3.37852e+08 3.36476e+08]\n",
      "[[ 5.44903e-06 -7.18126e-06 -2.32861e-05 ...  1.17157e-03  3.70124e-03 -3.71298e-03]\n",
      " [-6.53237e-06  6.45604e-06  7.23129e-06 ...  4.39756e-03  1.25853e-03  9.96697e-04]\n",
      " [ 1.45524e-05 -7.21100e-06 -2.33295e-05 ...  7.44863e-03  7.44766e-03 -4.16233e-03]\n",
      " [ 7.94391e-06  4.48932e-05 -8.15404e-06 ... -4.68911e-03  2.85591e-03 -2.90643e-03]\n",
      " [-6.64980e-06 -1.88985e-07 -1.97219e-05 ...  4.93046e-03  4.89242e-03 -8.78050e-04]]\n"
     ]
    }
   ],
   "source": [
    "N_dim, N_samples = (10**5, 16)\n",
    "pca = spax.PCA_m(5, devices = jax.devices(\"gpu\"))\n",
    "data = np.random.normal(0, 1, size = (N_dim, N_samples)) * np.sqrt(np.arange(1, N_dim + 1))[:, np.newaxis]\n",
    "tic = datetime.now()\n",
    "pca.fit(data, batch_size = N_dim // 2, centering_data = \"GPU\") # N_dim % (N_devices * batch_size) == 0\n",
    "print(\"DURATION:\", datetime.now() - tic)\n",
    "sampled_data = pca.sample(10**4, batch_size = N_dim // 2)\n",
    "print(np.std(pca.transform(data, batch_size = N_dim // 2), axis = 1)**2)\n",
    "print(np.std(pca.transform(sampled_data, batch_size = N_dim // 2), axis = 1)**2)\n",
    "print(pca.λ ** 2)\n",
    "print(pca.U.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION: 0:00:00.176588\n",
      "[3.19257e+08 3.18094e+08 3.17750e+08 3.16735e+08 3.15445e+08]\n",
      "[3.37049e+08 3.40065e+08 3.36460e+08 3.38864e+08 3.35254e+08]\n",
      "[3.40541e+08 3.39300e+08 3.38933e+08 3.37851e+08 3.36475e+08]\n",
      "[[ 5.44923e-06 -7.18217e-06 -2.32867e-05 ...  1.17190e-03  3.70141e-03 -3.71311e-03]\n",
      " [ 6.52941e-06 -6.45714e-06 -7.22693e-06 ... -4.39888e-03 -1.26010e-03 -9.96016e-04]\n",
      " [ 1.45554e-05 -7.20253e-06 -2.33319e-05 ...  7.44681e-03  7.44791e-03 -4.16299e-03]\n",
      " [-7.94253e-06 -4.48929e-05  8.14821e-06 ...  4.69115e-03 -2.85369e-03  2.90554e-03]\n",
      " [ 6.64819e-06  1.85479e-07  1.97229e-05 ... -4.93024e-03 -4.89275e-03  8.78251e-04]]\n"
     ]
    }
   ],
   "source": [
    "pca_sk = PCA(n_components = 5)\n",
    "tic = datetime.now()\n",
    "pca_sk.fit(data.T)\n",
    "print(\"DURATION:\", datetime.now() - tic)\n",
    "print(np.std(pca_sk.transform(data.T), axis = 0)**2)\n",
    "print(np.std(pca_sk.transform(sampled_data.T), axis = 0)**2)\n",
    "print(pca_sk.singular_values_**2 / (N_samples - 1))\n",
    "print(pca_sk.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test save + load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 42476.547 138688.97  -25199.688  -5766.743  30936.84 ]\n",
      "[ 42476.547 138688.94  -25199.688  -5766.748  30936.838]\n",
      "[  42477.39484 -138682.33761  -25228.97732    5778.40298  -30929.59941]\n"
     ]
    }
   ],
   "source": [
    "pca.save(\"test.hdf5\")\n",
    "pca_new = spax.PCA_m(5, devices = jax.devices(\"gpu\"))\n",
    "pca_new.load(\"test.hdf5\")\n",
    "\n",
    "x0 = np.arange(100000)[:, np.newaxis]\n",
    "print(pca.transform(x0).flatten())\n",
    "print(pca_new.transform(x0).flatten())\n",
    "print(pca_sk.transform(x0.T).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
